{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e34fe5",
   "metadata": {},
   "source": [
    "# Limpieza y EDA simulado con datos de claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5332e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe527671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_evaporation_sum</th>\n",
       "      <th>estacion_verano</th>\n",
       "      <th>estacion_oto√±o</th>\n",
       "      <th>estacion_invierno</th>\n",
       "      <th>estacion_primavera</th>\n",
       "      <th>temperat_2m</th>\n",
       "      <th>runoff_sum</th>\n",
       "      <th>volumetric_soil_water_layer_1</th>\n",
       "      <th>precipitation_sum_open_meteo</th>\n",
       "      <th>precipitation_d_1</th>\n",
       "      <th>...</th>\n",
       "      <th>suelo_lagunas</th>\n",
       "      <th>suelo_alfisoles</th>\n",
       "      <th>suelo_inceptisoles</th>\n",
       "      <th>suelo_rio</th>\n",
       "      <th>suelo_salinas</th>\n",
       "      <th>suelo_ultisoles</th>\n",
       "      <th>suelo_vertisoles</th>\n",
       "      <th>suelo_medano</th>\n",
       "      <th>suelo_esteros</th>\n",
       "      <th>inundacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0042</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>298.5</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.25</td>\n",
       "      <td>45.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0055</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>301.2</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.18</td>\n",
       "      <td>22.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>288.3</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.38</td>\n",
       "      <td>156.8</td>\n",
       "      <td>42.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>276.8</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.42</td>\n",
       "      <td>98.4</td>\n",
       "      <td>18.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>290.5</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.35</td>\n",
       "      <td>112.3</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_evaporation_sum  estacion_verano  estacion_oto√±o  estacion_invierno  \\\n",
       "0                 0.0042                1               0                  0   \n",
       "1                 0.0055                1               0                  0   \n",
       "2                 0.0018                0               1                  0   \n",
       "3                 0.0012                0               0                  1   \n",
       "4                 0.0028                0               0                  0   \n",
       "\n",
       "   estacion_primavera  temperat_2m  runoff_sum  volumetric_soil_water_layer_1  \\\n",
       "0                   0        298.5       0.012                           0.25   \n",
       "1                   0        301.2       0.008                           0.18   \n",
       "2                   0        288.3       0.045                           0.38   \n",
       "3                   0        276.8       0.028                           0.42   \n",
       "4                   1        290.5       0.035                           0.35   \n",
       "\n",
       "   precipitation_sum_open_meteo  precipitation_d_1  ...  suelo_lagunas  \\\n",
       "0                          45.2                8.5  ...              0   \n",
       "1                          22.7                3.2  ...              0   \n",
       "2                         156.8               42.5  ...              0   \n",
       "3                          98.4               18.3  ...              0   \n",
       "4                         112.3               25.4  ...              0   \n",
       "\n",
       "   suelo_alfisoles  suelo_inceptisoles  suelo_rio  suelo_salinas  \\\n",
       "0                0                   0          0              0   \n",
       "1                0                   0          0              0   \n",
       "2                0                   1          0              0   \n",
       "3                1                   0          0              0   \n",
       "4                0                   0          0              0   \n",
       "\n",
       "   suelo_ultisoles  suelo_vertisoles  suelo_medano  suelo_esteros  inundacion  \n",
       "0                0                 0             0              0       False  \n",
       "1                0                 0             0              0       False  \n",
       "2                0                 0             0              0        True  \n",
       "3                0                 0             0              0       False  \n",
       "4                0                 0             0              0       False  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"juguete_final.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390aa7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_evaporation_sum</th>\n",
       "      <th>estacion_verano</th>\n",
       "      <th>estacion_oto√±o</th>\n",
       "      <th>estacion_invierno</th>\n",
       "      <th>estacion_primavera</th>\n",
       "      <th>temperat_2m</th>\n",
       "      <th>runoff_sum</th>\n",
       "      <th>volumetric_soil_water_layer_1</th>\n",
       "      <th>precipitation_sum_open_meteo</th>\n",
       "      <th>precipitation_d_1</th>\n",
       "      <th>...</th>\n",
       "      <th>suelo_lagunas</th>\n",
       "      <th>suelo_alfisoles</th>\n",
       "      <th>suelo_inceptisoles</th>\n",
       "      <th>suelo_rio</th>\n",
       "      <th>suelo_salinas</th>\n",
       "      <th>suelo_ultisoles</th>\n",
       "      <th>suelo_vertisoles</th>\n",
       "      <th>suelo_medano</th>\n",
       "      <th>suelo_esteros</th>\n",
       "      <th>inundacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0042</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.35</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.25</td>\n",
       "      <td>45.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0055</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.05</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.18</td>\n",
       "      <td>22.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0018</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.15</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.38</td>\n",
       "      <td>156.8</td>\n",
       "      <td>42.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.42</td>\n",
       "      <td>98.4</td>\n",
       "      <td>18.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0028</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.35</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.35</td>\n",
       "      <td>112.3</td>\n",
       "      <td>25.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_evaporation_sum  estacion_verano  estacion_oto√±o  estacion_invierno  \\\n",
       "0                 0.0042                1               0                  0   \n",
       "1                 0.0055                1               0                  0   \n",
       "2                 0.0018                0               1                  0   \n",
       "3                 0.0012                0               0                  1   \n",
       "4                 0.0028                0               0                  0   \n",
       "\n",
       "   estacion_primavera  temperat_2m  runoff_sum  volumetric_soil_water_layer_1  \\\n",
       "0                   0        25.35       0.012                           0.25   \n",
       "1                   0        28.05       0.008                           0.18   \n",
       "2                   0        15.15       0.045                           0.38   \n",
       "3                   0         3.65       0.028                           0.42   \n",
       "4                   1        17.35       0.035                           0.35   \n",
       "\n",
       "   precipitation_sum_open_meteo  precipitation_d_1  ...  suelo_lagunas  \\\n",
       "0                          45.2                8.5  ...              0   \n",
       "1                          22.7                3.2  ...              0   \n",
       "2                         156.8               42.5  ...              0   \n",
       "3                          98.4               18.3  ...              0   \n",
       "4                         112.3               25.4  ...              0   \n",
       "\n",
       "   suelo_alfisoles  suelo_inceptisoles  suelo_rio  suelo_salinas  \\\n",
       "0                0                   0          0              0   \n",
       "1                0                   0          0              0   \n",
       "2                0                   1          0              0   \n",
       "3                1                   0          0              0   \n",
       "4                0                   0          0              0   \n",
       "\n",
       "   suelo_ultisoles  suelo_vertisoles  suelo_medano  suelo_esteros  inundacion  \n",
       "0                0                 0             0              0       False  \n",
       "1                0                 0             0              0       False  \n",
       "2                0                 0             0              0        True  \n",
       "3                0                 0             0              0       False  \n",
       "4                0                 0             0              0       False  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['temperat_2m'] = (df['temperat_2m'] - 273.15).round(2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb8d0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas disponibles:\n",
      " ['total_evaporation_sum', 'estacion_verano', 'estacion_oto√±o', 'estacion_invierno', 'estacion_primavera', 'temperat_2m', 'runoff_sum', 'volumetric_soil_water_layer_1', 'precipitation_sum_open_meteo', 'precipitation_d_1', 'precipitation_d_2', 'precipitation_d_3', 'precipitation_d_4', 'precipitation_d_5', 'precipitation_d_6', 'suelo_roca', 'suelo_entisoles', 'suelo_miscelaneas', 'suelo_molisoles', 'suelo_aridisoles', 'suelo_complejo_indiferenci', 'suelo_lagunas', 'suelo_alfisoles', 'suelo_inceptisoles', 'suelo_rio', 'suelo_salinas', 'suelo_ultisoles', 'suelo_vertisoles', 'suelo_medano', 'suelo_esteros', 'inundacion']\n",
      "Shape del dataframe: (15, 31)\n",
      "\n",
      "Target: inundacion\n",
      "Features: 30 columnas\n",
      "\n",
      "Shapes: X=(15, 30), y=(15,)\n",
      "Distribuci√≥n del target: [9 6] (0=False, 1=True)\n",
      "\n",
      "Shapes despu√©s del split:\n",
      "  X_train=(12, 30), y_train=(12,)\n",
      "  X_test=(3, 30), y_test=(3,)\n",
      "\n",
      "‚úì Datos escalados y listos para el modelo!\n"
     ]
    }
   ],
   "source": [
    "# Preparar entradas (X) y salida (y) para el modelo\n",
    "# - Target: columna 'inundacion' (True/False ‚Üí 1/0)\n",
    "# - Features: todas las dem√°s columnas (ya limpias y encodeadas)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"Columnas disponibles:\\n\", df.columns.tolist())\n",
    "print(\"Shape del dataframe:\", df.shape)\n",
    "\n",
    "# --- Definir target y features ---\n",
    "target = 'inundacion'\n",
    "features = [col for col in df.columns if col != target]\n",
    "\n",
    "print(f\"\\nTarget: {target}\")\n",
    "print(f\"Features: {len(features)} columnas\")\n",
    "\n",
    "# --- Preparar X (features) y y (target) ---\n",
    "X = df[features].to_numpy(dtype=float)\n",
    "y = df[target].to_numpy()\n",
    "\n",
    "# Convertir True/False a 1/0\n",
    "y = y.astype(int)\n",
    "\n",
    "print(f\"\\nShapes: X={X.shape}, y={y.shape}\")\n",
    "print(f\"Distribuci√≥n del target: {np.bincount(y)} (0=False, 1=True)\")\n",
    "\n",
    "# --- Split train/test con estratificaci√≥n ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nShapes despu√©s del split:\")\n",
    "print(f\"  X_train={X_train.shape}, y_train={y_train.shape}\")\n",
    "print(f\"  X_test={X_test.shape}, y_test={y_test.shape}\")\n",
    "\n",
    "# --- Escalado (StandardScaler) ---\n",
    "# IMPORTANTE: El escalado es crucial para redes neuronales porque:\n",
    "# - Acelera la convergencia del entrenamiento\n",
    "# - Evita que variables con rangos grandes dominen el aprendizaje\n",
    "# - Mejora la estabilidad num√©rica y el rendimiento de las funciones de activaci√≥n\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n‚úì Datos escalados y listos para el modelo!\")\n",
    "\n",
    "# --- Variables listas para usar ---\n",
    "# X_train_scaled, X_test_scaled  -> datos de entrada escalados\n",
    "# y_train, y_test                -> etiquetas binarias (0/1)\n",
    "# scaler                         -> para transformar datos nuevos en producci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fdeed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 Complete [00h 03m 44s]\n",
      "val_auc: 1.0\n",
      "\n",
      "Best val_auc So Far: 1.0\n",
      "Total elapsed time: 00h 20m 45s\n",
      "\n",
      "Search: Running Trial #7\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "6                 |4                 |n_layers\n",
      "208               |32                |units_0\n",
      "relu              |elu               |activation_0\n",
      "0                 |0                 |dropout_0\n",
      "0.01              |0.001             |learning_rate\n",
      "rmsprop           |sgd               |optimizer\n",
      "128               |8                 |units_1\n",
      "relu              |relu              |activation_1\n",
      "0.4               |0                 |dropout_1\n",
      "88                |8                 |units_2\n",
      "elu               |relu              |activation_2\n",
      "0                 |0                 |dropout_2\n",
      "248               |8                 |units_3\n",
      "relu              |relu              |activation_3\n",
      "0                 |0                 |dropout_3\n",
      "96                |None              |units_4\n",
      "relu              |None              |activation_4\n",
      "0.3               |None              |dropout_4\n",
      "\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - accuracy: 0.3333 - auc: 0.5556 - loss: 0.7296 - val_accuracy: 0.3333 - val_auc: 0.0000e+00 - val_loss: 1.4831\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9s/step - accuracy: 0.3333 - auc: 0.5556 - loss: 0.7296 - val_accuracy: 0.3333 - val_auc: 0.0000e+00 - val_loss: 1.4831\n",
      "Epoch 2/100\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6667 - auc: 0.4444 - loss: 0.8081 - val_accuracy: 0.6667 - val_auc: 1.0000 - val_loss: 0.6686\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6667 - auc: 0.4444 - loss: 0.8081 - val_accuracy: 0.6667 - val_auc: 1.0000 - val_loss: 0.6686\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step - accuracy: 0.3333 - auc: 0.7222 - loss: 1.9741 - val_accuracy: 0.3333 - val_auc: 1.0000 - val_loss: 2.4486\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step - accuracy: 0.3333 - auc: 0.7222 - loss: 1.9741 - val_accuracy: 0.3333 - val_auc: 1.0000 - val_loss: 2.4486\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step - accuracy: 0.6667 - auc: 1.0000 - loss: 0.6670 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 0.0468\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step - accuracy: 0.6667 - auc: 1.0000 - loss: 0.6670 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 0.0468\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8889 - auc: 1.0000 - loss: 0.1821 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 0.0510\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.8889 - auc: 1.0000 - loss: 0.1821 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 0.0510\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0607 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 9.2771e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0607 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 9.2771e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7376e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 6.5609e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.7376e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 6.5609e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 8.2652e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 4.4196e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 8.2652e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 4.4196e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 3.4447e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 4.3588e-05\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 3.4447e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 4.3588e-05\n",
      "Epoch 10/100\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 7.2174e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 4.2024e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 7.2174e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 4.2024e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 2.5149e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 2.5149e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0517e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 2.1905e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 813ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.0517e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 2.1905e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3446e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 2.0717e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.3446e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 2.0717e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.5651e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.9896e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.5651e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.9896e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 6.5466e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.9178e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 6.5466e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.9178e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.1197e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.8949e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 801ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 2.1197e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.8949e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 9.4585e-06 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.8762e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 9.4585e-06 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.8762e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 3.9251e-06 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.8691e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 810ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 3.9251e-06 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.8691e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0563e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.6261e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0563e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.6261e-05\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8394e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.4291e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8394e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.4291e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4184e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.4226e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.4184e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.4226e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 5.9540e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.2571e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 5.9540e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 1.2571e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 4.7623e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 9.2458e-06\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 671ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 4.7623e-04 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 9.2458e-06\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8012e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 8.9201e-06\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.8012e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 8.9201e-06\n",
      "Epoch 25/100\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0741e-06 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 8.9153e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 1.0741e-06 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 8.9153e-06\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 4.0290e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 8.4160e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 4.0290e-05 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 8.4160e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454ms/step - accuracy: 1.0000 - auc: 1.0000 - loss: 7.9178e-07"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 97\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müîç Iniciando b√∫squeda de hiperpar√°metros...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEsto puede tomar varios minutos dependiendo de tu hardware.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[43mtuner\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 20% del train para validaci√≥n\u001b[39;49;00m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    103\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# Obtener los mejores hiperpar√°metros\u001b[39;00m\n\u001b[32m    106\u001b[39m best_hps = tuner.get_best_hyperparameters(num_trials=\u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[39m, in \u001b[36mBaseTuner.search\u001b[39m\u001b[34m(self, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_begin(trial)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_trial_end(trial)\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.on_search_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:274\u001b[39m, in \u001b[36mBaseTuner._try_run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m    273\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m         trial.status = trial_module.TrialStatus.COMPLETED\n\u001b[32m    276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:239\u001b[39m, in \u001b[36mBaseTuner._run_and_update_trial\u001b[39m\u001b[34m(self, trial, *fit_args, **fit_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, *fit_args, **fit_kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[32m    241\u001b[39m         \u001b[38;5;28mself\u001b[39m.oracle.objective.name\n\u001b[32m    242\u001b[39m     ):\n\u001b[32m    243\u001b[39m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[32m    244\u001b[39m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[32m    245\u001b[39m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[32m    246\u001b[39m         warnings.warn(\n\u001b[32m    247\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe use case of calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    254\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    255\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\tuner.py:314\u001b[39m, in \u001b[36mTuner.run_trial\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    312\u001b[39m     callbacks.append(model_checkpoint)\n\u001b[32m    313\u001b[39m     copied_kwargs[\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m] = callbacks\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m     obj_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     histories.append(obj_value)\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\tuner.py:233\u001b[39m, in \u001b[36mTuner._build_and_fit_model\u001b[39m\u001b[34m(self, trial, *args, **kwargs)\u001b[39m\n\u001b[32m    231\u001b[39m hp = trial.hyperparameters\n\u001b[32m    232\u001b[39m model = \u001b[38;5;28mself\u001b[39m._try_build(hp)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.config.multi_backend():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py:149\u001b[39m, in \u001b[36mHyperModel.fit\u001b[39m\u001b[34m(self, hp, model, *args, **kwargs)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, *args, **kwargs):\n\u001b[32m    126\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:375\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    373\u001b[39m callbacks.on_epoch_begin(epoch)\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator.catch_stop_iteration():\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbegin_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbegin_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:742\u001b[39m, in \u001b[36mTFEpochIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_epoch_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:125\u001b[39m, in \u001b[36mEpochIterator._enumerate_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    119\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m (\n\u001b[32m    120\u001b[39m             step,\n\u001b[32m    121\u001b[39m             step + \u001b[38;5;28mself\u001b[39m.steps_per_execution - \u001b[32m1\u001b[39m,\n\u001b[32m    122\u001b[39m             \u001b[38;5;28mself\u001b[39m._current_iterator,\n\u001b[32m    123\u001b[39m         )\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_batches \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._steps_seen >= \u001b[38;5;28mself\u001b[39m._num_batches:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m         \u001b[38;5;28mself\u001b[39m._current_iterator = \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m         \u001b[38;5;28mself\u001b[39m._steps_seen = \u001b[32m0\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:501\u001b[39m, in \u001b[36mDatasetV2.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context.executing_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops.inside_function():\n\u001b[32m    500\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    503\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33miteration in eager mode or within tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:709\u001b[39m, in \u001b[36mOwnedIterator.__init__\u001b[39m\u001b[34m(self, dataset, components, element_spec)\u001b[39m\n\u001b[32m    705\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    707\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    708\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnot be specified.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[38;5;28mself\u001b[39m._get_next_call_count = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:748\u001b[39m, in \u001b[36mOwnedIterator._create_iterator\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    745\u001b[39m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype.args[\u001b[32m0\u001b[39m].args[\u001b[32m0\u001b[39m].args) == \u001b[38;5;28mlen\u001b[39m(\n\u001b[32m    746\u001b[39m       \u001b[38;5;28mself\u001b[39m._flat_output_types)\n\u001b[32m    747\u001b[39m   \u001b[38;5;28mself\u001b[39m._iterator_resource.op.experimental_set_type(fulltype)\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3478\u001b[39m, in \u001b[36mmake_iterator\u001b[39m\u001b[34m(dataset, iterator, name)\u001b[39m\n\u001b[32m   3476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   3477\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3478\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3479\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMakeIterator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   3481\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# B√∫squeda de hiperpar√°metros con Keras Tuner\n",
    "# Vamos a explorar diferentes arquitecturas de red neuronal para clasificaci√≥n binaria\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as kr\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Definir la funci√≥n que construye el modelo con hiperpar√°metros variables\n",
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Construye un modelo con hiperpar√°metros a optimizar:\n",
    "    - N√∫mero de capas ocultas\n",
    "    - N√∫mero de neuronas por capa\n",
    "    - Tasa de dropout\n",
    "    - Learning rate\n",
    "    - Activaci√≥n en capas ocultas\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Capa de entrada (debe coincidir con el n√∫mero de features)\n",
    "    input_dim = X_train_scaled.shape[1]\n",
    "    \n",
    "    # N√∫mero de capas ocultas a probar (1 a 6 capas)\n",
    "    n_layers = hp.Int('n_layers', min_value=1, max_value=6, step=1)\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        # N√∫mero de neuronas por capa (entre 8 y 256, en potencias de 2)\n",
    "        units = hp.Int(f'units_{i}', min_value=8, max_value=256, step=8)\n",
    "        \n",
    "        # Funci√≥n de activaci√≥n\n",
    "        activation = hp.Choice(f'activation_{i}', values=['relu', 'tanh', 'elu'])\n",
    "        \n",
    "        if i == 0:\n",
    "            # Primera capa necesita especificar input_dim\n",
    "            model.add(layers.Dense(units, activation=activation, input_dim=input_dim))\n",
    "        else:\n",
    "            model.add(layers.Dense(units, activation=activation))\n",
    "        \n",
    "        # Dropout para regularizaci√≥n (0.0 a 0.5)\n",
    "        dropout_rate = hp.Float(f'dropout_{i}', min_value=0.0, max_value=0.5, step=0.1)\n",
    "        if dropout_rate > 0:\n",
    "            model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    # Capa de salida (clasificaci√≥n binaria con sigmoid)\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Learning rate variable\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    # Optimizador a probar\n",
    "    optimizer_name = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop'])\n",
    "    \n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    else:\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    \n",
    "    # Compilar el modelo\n",
    "    # Para clasificaci√≥n binaria: binary_crossentropy es mejor que mse\n",
    "    # M√âTRICAS CLAVE:\n",
    "    # - Recall (sensibilidad): Prioridad #1 para detectar TODAS las inundaciones\n",
    "    # - Precision: Evitar demasiadas falsas alarmas\n",
    "    # - AUC: Balance general\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "# OBJETIVO: Maximizar RECALL en validaci√≥n\n",
    "# Raz√≥n: En predicci√≥n de inundaciones, es CR√çTICO detectar todas las inundaciones (recall alto)\n",
    "# Preferimos \"falsas alarmas\" (falsos positivos) antes que \"no avisar\" (falsos negativos)\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=kt.Objective('val_recall', direction='max'),  # ¬°MAXIMIZAR RECALL!\n",
    "    max_trials=20,  # N√∫mero de combinaciones a probar (puedes aumentar a 50-100 si ten√©s tiempo)\n",
    "    executions_per_trial=2,  # Ejecutar cada configuraci√≥n 2 veces para estabilidad\n",
    "    directory='hyperparameter_tuning',\n",
    "    project_name='inundacion_classifier',\n",
    "    overwrite=True\n",
    ")\n",
    "    max_trials=20,  # N√∫mero de combinaciones a probar (puedes aumentar a 50-100 si ten√©s tiempo)\n",
    "print(\"Espacio de b√∫squeda de hiperpar√°metros:\")\n",
    "print(tuner.search_space_summary())\n",
    "\n",
    "# Configurar callbacks para el entrenamiento\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Ejecutar la b√∫squeda\n",
    "print(\"\\nüîç Iniciando b√∫squeda de hiperpar√°metros...\")\n",
    "print(\"Esto puede tomar varios minutos dependiendo de tu hardware.\\n\")\n",
    "\n",
    "tuner.search(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,  # 20% del train para validaci√≥n\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "    X_train_scaled, y_train,\n",
    "# Obtener los mejores hiperpar√°metros\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÜ MEJORES HIPERPAR√ÅMETROS ENCONTRADOS:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"N√∫mero de capas: {best_hps.get('n_layers')}\")\n",
    "for i in range(best_hps.get('n_layers')):\n",
    "    print(f\"  Capa {i+1}: {best_hps.get(f'units_{i}')} neuronas, \"\n",
    "          f\"activaci√≥n={best_hps.get(f'activation_{i}')}, \"\n",
    "          f\"dropout={best_hps.get(f'dropout_{i}')}\")\n",
    "print(f\"Optimizer: {best_hps.get('optimizer')}\")\n",
    "print(f\"Learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Construir y entrenar el mejor modelo\n",
    "print(\"\\nüìä Entrenando el mejor modelo en todo el conjunto de entrenamiento...\")\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "history = best_model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluar en el conjunto de test\n",
    "print(\"\\nüìà Evaluaci√≥n en el conjunto de test:\")\n",
    "print(f\"Test Recall: {test_results[2]:.4f}  ‚Üê ¬°M√©trica principal!\")\n",
    "print(f\"Test Precision: {test_results[3]:.4f}\")\n",
    "print(f\"Test AUC: {test_results[4]:.4f}\")\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "\n",
    "best_model.save('mejor_modelo_inundacion.h5')\n",
    "# Guardar el mejor modelo\n",
    "print(\"\\nüìà Evaluaci√≥n en el conjunto de test:\")print(\"\\n‚úÖ Modelo guardado como 'mejor_modelo_inundacion.h5'\")\n",
    "\n",
    "print(\"\\n‚úÖ Modelo guardado como 'mejor_modelo_inundacion.h5'\")\n",
    "best_model.save('mejor_modelo_inundacion.h5')\n",
    "test_results = best_model.evaluate(X_test_scaled, y_test, verbose=0)best_model.save('mejor_modelo_inundacion.h5')\n",
    "\n",
    "print(\"\\n‚úÖ Modelo guardado como 'mejor_modelo_inundacion.h5'\")\n",
    "print(f\"Test Loss: {test_results[0]:.4f}\")# Guardar el mejor modelo\n",
    "\n",
    "print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
    "print(f\"Test AUC: {test_results[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de resultados del entrenamiento\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Graficar la evoluci√≥n del entrenamiento\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history.history['loss'], label='Train Loss')\n",
    "axes[0].plot(history.history['val_loss'], label='Val Loss')\n",
    "axes[0].set_title('Evoluci√≥n de la Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Binary Crossentropy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history.history['accuracy'], label='Train Accuracy')\n",
    "axes[1].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "axes[1].set_title('Evoluci√≥n de la Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# AUC\n",
    "axes[2].plot(history.history['auc'], label='Train AUC')\n",
    "axes[2].plot(history.history['val_auc'], label='Val AUC')\n",
    "axes[2].set_title('Evoluci√≥n del AUC')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('AUC')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Matriz de confusi√≥n en el conjunto de test\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred_proba = best_model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Inundaci√≥n', 'Inundaci√≥n'],\n",
    "            yticklabels=['No Inundaci√≥n', 'Inundaci√≥n'])\n",
    "plt.title('Matriz de Confusi√≥n - Conjunto de Test')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Predicci√≥n')\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificaci√≥n\n",
    "print(\"\\nüìä Reporte de Clasificaci√≥n:\")\n",
    "print(classification_report(y_test, y_pred, \n",
    "                          target_names=['No Inundaci√≥n', 'Inundaci√≥n'],\n",
    "                          digits=4))\n",
    "\n",
    "# Mostrar el resumen del mejor modelo\n",
    "print(\"\\nüèóÔ∏è Arquitectura del mejor modelo:\")\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a12c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Predicciones con probabilidades\n",
    "# El modelo devuelve un valor entre 0 y 1 que representa la probabilidad de inundaci√≥n\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä PREDICCIONES CON PROBABILIDADES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Obtener probabilidades para el conjunto de test\n",
    "probabilidades = best_model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Mostrar ejemplos de predicciones\n",
    "print(\"\\nEjemplos de predicciones (primeros 20 casos del test):\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'√çndice':<8} {'Probabilidad':<15} {'Predicci√≥n':<15} {'Real':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i in range(min(20, len(y_test))):\n",
    "    prob = probabilidades[i]\n",
    "    pred_class = \"Inundaci√≥n ‚úì\" if prob > 0.5 else \"No Inundaci√≥n ‚úó\"\n",
    "    real_class = \"Inundaci√≥n\" if y_test[i] == 1 else \"No Inundaci√≥n\"\n",
    "    correcto = \"‚úì\" if (prob > 0.5) == (y_test[i] == 1) else \"‚úó\"\n",
    "    \n",
    "    print(f\"{i:<8} {prob:>6.4f} (={prob*100:5.1f}%)   {pred_class:<15} {real_class:<10} {correcto}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Distribuci√≥n de probabilidades\n",
    "print(\"\\nüìà Distribuci√≥n de probabilidades predichas:\")\n",
    "print(f\"  M√≠nimo: {probabilidades.min():.4f}\")\n",
    "print(f\"  M√°ximo: {probabilidades.max():.4f}\")\n",
    "print(f\"  Media: {probabilidades.mean():.4f}\")\n",
    "print(f\"  Mediana: {np.median(probabilidades):.4f}\")\n",
    "\n",
    "# Histograma de probabilidades\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(probabilidades[y_test == 0], bins=30, alpha=0.7, label='No Inundaci√≥n (real)', color='blue', edgecolor='black')\n",
    "plt.hist(probabilidades[y_test == 1], bins=30, alpha=0.7, label='Inundaci√≥n (real)', color='red', edgecolor='black')\n",
    "plt.axvline(x=0.5, color='green', linestyle='--', linewidth=2, label='Umbral (0.5)')\n",
    "plt.xlabel('Probabilidad predicha de Inundaci√≥n')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribuci√≥n de Probabilidades por Clase Real')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(range(len(probabilidades)), probabilidades, \n",
    "           c=y_test, cmap='RdBu_r', alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "plt.axhline(y=0.5, color='green', linestyle='--', linewidth=2, label='Umbral (0.5)')\n",
    "plt.xlabel('√çndice de muestra')\n",
    "plt.ylabel('Probabilidad predicha')\n",
    "plt.title('Probabilidades predichas vs Clase Real')\n",
    "plt.colorbar(label='Clase Real (0=No, 1=S√≠)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚ÑπÔ∏è  INTERPRETACI√ìN:\")\n",
    "print(\"=\"*70)\n",
    "print(\"‚Ä¢ El modelo devuelve un valor entre 0.0 y 1.0\")\n",
    "print(\"‚Ä¢ 0.0 = 0% de probabilidad de inundaci√≥n (casi seguro que NO)\")\n",
    "print(\"‚Ä¢ 0.5 = 50% de probabilidad (umbral de decisi√≥n)\")\n",
    "print(\"‚Ä¢ 1.0 = 100% de probabilidad de inundaci√≥n (casi seguro que S√ç)\")\n",
    "print(\"‚Ä¢ Valores cercanos a 0 o 1 indican alta confianza\")\n",
    "print(\"‚Ä¢ Valores cerca de 0.5 indican incertidumbre\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Funci√≥n auxiliar para hacer predicciones individuales\n",
    "def predecir_inundacion(datos_nuevos, mostrar_detalle=True):\n",
    "    \"\"\"\n",
    "    Predice la probabilidad de inundaci√≥n para datos nuevos.\n",
    "    \n",
    "    Args:\n",
    "        datos_nuevos: array o DataFrame con las mismas features que el entrenamiento\n",
    "        mostrar_detalle: si True, muestra interpretaci√≥n detallada\n",
    "    \n",
    "    Returns:\n",
    "        probabilidad: valor entre 0 y 1\n",
    "    \"\"\"\n",
    "    # Escalar los datos nuevos\n",
    "    datos_escalados = scaler.transform(datos_nuevos)\n",
    "    \n",
    "    # Predecir\n",
    "    prob = best_model.predict(datos_escalados, verbose=0).flatten()[0]\n",
    "    \n",
    "    if mostrar_detalle:\n",
    "        print(f\"\\nüîÆ Predicci√≥n:\")\n",
    "        print(f\"   Probabilidad de inundaci√≥n: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "        print(f\"   Probabilidad de NO inundaci√≥n: {1-prob:.4f} ({(1-prob)*100:.2f}%)\")\n",
    "        \n",
    "        if prob > 0.8:\n",
    "            print(f\"   ‚ö†Ô∏è  ALTA probabilidad de inundaci√≥n\")\n",
    "        elif prob > 0.5:\n",
    "            print(f\"   ‚ö° Probabilidad moderada de inundaci√≥n\")\n",
    "        elif prob > 0.2:\n",
    "            print(f\"   ‚úì Baja probabilidad de inundaci√≥n\")\n",
    "        else:\n",
    "            print(f\"   ‚úì‚úì MUY baja probabilidad de inundaci√≥n\")\n",
    "    \n",
    "    return prob\n",
    "\n",
    "print(\"\\nüí° Para usar el modelo con nuevos datos:\")\n",
    "print(\"   probabilidad = predecir_inundacion(datos_nuevos)\")\n",
    "print(\"   donde 'datos_nuevos' debe tener las mismas columnas que X_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a86ac15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
